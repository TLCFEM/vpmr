diff --git a/Eigen/src/Core/AssignEvaluator.h b/Eigen/src/Core/AssignEvaluator.h
index 36f0a9d74..13b31110c 100644
--- a/Eigen/src/Core/AssignEvaluator.h
+++ b/Eigen/src/Core/AssignEvaluator.h
@@ -558,10 +558,11 @@ struct dense_assignment_loop_impl<Kernel, InnerVectorizedTraversal, InnerUnrolli
 /***********************
 *** Linear traversal ***
 ***********************/
-
+static tbb::affinity_partitioner ap;
 template <typename Kernel>
 struct dense_assignment_loop_impl<Kernel, LinearTraversal, NoUnrolling> {
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE constexpr void run(Kernel& kernel) {
+    return tbb::parallel_for(Index(0), kernel.size(), [&](const Index l) { kernel.assignCoeff(l); }, ap);
     const Index size = kernel.size();
     for (Index i = 0; i < size; ++i) kernel.assignCoeff(i);
   }
diff --git a/Eigen/src/Core/products/GeneralBlockPanelKernel.h b/Eigen/src/Core/products/GeneralBlockPanelKernel.h
index e72c6b48e..a72e7e53e 100644
--- a/Eigen/src/Core/products/GeneralBlockPanelKernel.h
+++ b/Eigen/src/Core/products/GeneralBlockPanelKernel.h
@@ -1466,7 +1466,8 @@ EIGEN_DONT_INLINE void gebp_kernel<LhsScalar, RhsScalar, Index, DataMapper, mr,
     const Index actual_panel_rows =
         (3 * LhsProgress) * std::max<Index>(1, ((l1 - sizeof(ResScalar) * mr * nr - depth * nr * sizeof(RhsScalar)) /
                                                 (depth * sizeof(LhsScalar) * 3 * LhsProgress)));
-    for (Index i1 = 0; i1 < peeled_mc3; i1 += actual_panel_rows) {
+    tbb::parallel_for(Index(0), (peeled_mc3 + actual_panel_rows - 1) / actual_panel_rows, [&](Index i1) {
+      i1 *= actual_panel_rows;
       const Index actual_panel_end = (std::min)(i1 + actual_panel_rows, peeled_mc3);
 #if EIGEN_ARCH_ARM64 || EIGEN_ARCH_LOONGARCH64
       EIGEN_IF_CONSTEXPR(nr >= 8) {
@@ -1921,7 +1922,7 @@ EIGEN_DONT_INLINE void gebp_kernel<LhsScalar, RhsScalar, Index, DataMapper, mr,
           r0.storePacket(2 * Traits::ResPacketSize, R2);
         }
       }
-    }
+    });
   }
 
   //---------- Process 2 * LhsProgress rows at once ----------
@@ -1934,7 +1935,8 @@ EIGEN_DONT_INLINE void gebp_kernel<LhsScalar, RhsScalar, Index, DataMapper, mr,
         (2 * LhsProgress) * std::max<Index>(1, ((l1 - sizeof(ResScalar) * mr * nr - depth * nr * sizeof(RhsScalar)) /
                                                 (depth * sizeof(LhsScalar) * 2 * LhsProgress)));
 
-    for (Index i1 = peeled_mc3; i1 < peeled_mc2; i1 += actual_panel_rows) {
+    tbb::parallel_for(peeled_mc3, (peeled_mc2 + actual_panel_rows - 1) / actual_panel_rows, [&](Index i1) {
+      i1 *= actual_panel_rows;
       Index actual_panel_end = (std::min)(i1 + actual_panel_rows, peeled_mc2);
 #if EIGEN_ARCH_ARM64 || EIGEN_ARCH_LOONGARCH64
       EIGEN_IF_CONSTEXPR(nr >= 8) {
@@ -2298,7 +2300,7 @@ EIGEN_DONT_INLINE void gebp_kernel<LhsScalar, RhsScalar, Index, DataMapper, mr,
           r0.storePacket(1 * Traits::ResPacketSize, R1);
         }
       }
-    }
+    });
   }
   //---------- Process 1 * LhsProgress rows at once ----------
   if (mr >= 1 * Traits::LhsProgress) {
diff --git a/Eigen/src/Core/products/GeneralMatrixVector.h b/Eigen/src/Core/products/GeneralMatrixVector.h
index ba72a8a4f..4ce9f99ab 100644
--- a/Eigen/src/Core/products/GeneralMatrixVector.h
+++ b/Eigen/src/Core/products/GeneralMatrixVector.h
@@ -150,30 +150,20 @@ general_matrix_vector_product<Index, LhsScalar, LhsMapper, ColMajor, ConjugateLh
     Index jend = numext::mini(j2 + block_cols, cols);
     Index i = 0;
     for (; i < n8; i += ResPacketSize * 8) {
-      ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
-                c2 = pset1<ResPacket>(ResScalar(0)), c3 = pset1<ResPacket>(ResScalar(0)),
-                c4 = pset1<ResPacket>(ResScalar(0)), c5 = pset1<ResPacket>(ResScalar(0)),
-                c6 = pset1<ResPacket>(ResScalar(0)), c7 = pset1<ResPacket>(ResScalar(0));
-
-      for (Index j = j2; j < jend; j += 1) {
-        RhsPacket b0 = pset1<RhsPacket>(rhs(j, 0));
-        c0 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 0, j), b0, c0);
-        c1 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 1, j), b0, c1);
-        c2 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 2, j), b0, c2);
-        c3 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 3, j), b0, c3);
-        c4 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 4, j), b0, c4);
-        c5 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 5, j), b0, c5);
-        c6 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 6, j), b0, c6);
-        c7 = pcj.pmadd(lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * 7, j), b0, c7);
+      for (auto x = 0; x < 8; ++x) {
+        const auto offset = i + ResPacketSize * x;
+        pstoreu(res + offset, pmadd(tbb::parallel_deterministic_reduce(
+                                        tbb::blocked_range<Index>(j2, jend), pset1<ResPacket>(ResScalar(0)),
+                                        [&](const tbb::blocked_range<Index>& r, ResPacket running_total) {
+                                          for (auto j = r.begin(); j < r.end(); ++j)
+                                            running_total += pcj.pmul(
+                                                lhs.template load<LhsPacket, LhsAlignment>(i + LhsPacketSize * x, j),
+                                                pset1<RhsPacket>(rhs(j, 0)));
+                                          return running_total;
+                                        },
+                                        std::plus<>()),
+                                    palpha, ploadu<ResPacket>(res + offset)));
       }
-      pstoreu(res + i + ResPacketSize * 0, pmadd(c0, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 0)));
-      pstoreu(res + i + ResPacketSize * 1, pmadd(c1, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 1)));
-      pstoreu(res + i + ResPacketSize * 2, pmadd(c2, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 2)));
-      pstoreu(res + i + ResPacketSize * 3, pmadd(c3, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 3)));
-      pstoreu(res + i + ResPacketSize * 4, pmadd(c4, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 4)));
-      pstoreu(res + i + ResPacketSize * 5, pmadd(c5, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 5)));
-      pstoreu(res + i + ResPacketSize * 6, pmadd(c6, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 6)));
-      pstoreu(res + i + ResPacketSize * 7, pmadd(c7, palpha, ploadu<ResPacket>(res + i + ResPacketSize * 7)));
     }
     if (i < n4) {
       ResPacket c0 = pset1<ResPacket>(ResScalar(0)), c1 = pset1<ResPacket>(ResScalar(0)),
diff --git a/Eigen/src/SVD/BDCSVD.h b/Eigen/src/SVD/BDCSVD.h
index 6fab905e5..6e254b19d 100644
--- a/Eigen/src/SVD/BDCSVD.h
+++ b/Eigen/src/SVD/BDCSVD.h
@@ -820,6 +820,16 @@ template <typename MatrixType, int Options>
 typename BDCSVD<MatrixType, Options>::RealScalar BDCSVD<MatrixType, Options>::secularEq(
     RealScalar mu, const ArrayRef& col0, const ArrayRef& diag, const IndicesRef& perm, const ArrayRef& diagShifted,
     RealScalar shift) {
+  return tbb::parallel_deterministic_reduce(
+      tbb::blocked_range<Index>(Index(0), perm.size()), RealScalar(1),
+      [&](const tbb::blocked_range<Index>& r, RealScalar running_total) {
+        for (auto i = r.begin(); i < r.end(); ++i) {
+          Index j = perm(i);
+          running_total += (col0(j) / (diagShifted(j) - mu)) * (col0(j) / (diag(j) + shift + mu));
+        }
+        return running_total;
+      },
+      std::plus<>());
   Index m = perm.size();
   RealScalar res = Literal(1);
   for (Index i = 0; i < m; ++i) {
@@ -1161,6 +1171,8 @@ template <typename MatrixType, int Options>
 void BDCSVD<MatrixType, Options>::computeSingVecs(const ArrayRef& zhat, const ArrayRef& diag, const IndicesRef& perm,
                                                   const VectorType& singVals, const ArrayRef& shifts,
                                                   const ArrayRef& mus, MatrixXr& U, MatrixXr& V) {
+  static tbb::affinity_partitioner ap;
+
   Index n = zhat.size();
   Index m = perm.size();
 
@@ -1170,10 +1182,13 @@ void BDCSVD<MatrixType, Options>::computeSingVecs(const ArrayRef& zhat, const Ar
       if (m_compV) V.col(k) = VectorType::Unit(n, k);
     } else {
       U.col(k).setZero();
-      for (Index l = 0; l < m; ++l) {
-        Index i = perm(l);
-        U(i, k) = zhat(i) / (((diag(i) - shifts(k)) - mus(k))) / ((diag(i) + singVals[k]));
-      }
+      tbb::parallel_for(
+          Index(0), m,
+          [&](const Index l) {
+            Index i = perm(l);
+            U(i, k) = zhat(i) / (((diag(i) - shifts(k)) - mus(k))) / ((diag(i) + singVals[k]));
+          },
+          ap);
       U(n, k) = Literal(0);
       U.col(k).normalize();
 
